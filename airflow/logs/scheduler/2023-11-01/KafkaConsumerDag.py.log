[2023-11-01T00:31:40.424+0000] {processor.py:157} INFO - Started process (PID=343955) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:31:40.424+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:31:40.425+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:31:40.425+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:31:40.447+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:31:40.435+0000] {dagbag.py:346} ERROR - Failed to import: /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
Traceback (most recent call last):
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py", line 6, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache.spark'
[2023-11-01T00:31:40.448+0000] {processor.py:841} WARNING - No viable dags retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:31:40.570+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.150 seconds
[2023-11-01T00:32:39.716+0000] {processor.py:157} INFO - Started process (PID=344716) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:32:39.717+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:32:39.718+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:32:39.718+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:32:39.724+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:32:39.722+0000] {dagbag.py:346} ERROR - Failed to import: /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
Traceback (most recent call last):
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py", line 6, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache.spark'
[2023-11-01T00:32:39.724+0000] {processor.py:841} WARNING - No viable dags retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:32:39.831+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.119 seconds
[2023-11-01T00:33:10.338+0000] {processor.py:157} INFO - Started process (PID=344895) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:33:10.340+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:33:10.340+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:33:10.340+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:33:10.344+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:33:10.343+0000] {dagbag.py:346} ERROR - Failed to import: /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
Traceback (most recent call last):
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py", line 6, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
ModuleNotFoundError: No module named 'airflow.providers.apache.spark'
[2023-11-01T00:33:10.344+0000] {processor.py:841} WARNING - No viable dags retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:33:10.395+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.060 seconds
[2023-11-01T00:34:16.630+0000] {processor.py:157} INFO - Started process (PID=345809) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:34:16.632+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:34:16.633+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:34:16.632+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:34:16.659+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:34:16.653+0000] {dagbag.py:346} ERROR - Failed to import: /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
Traceback (most recent call last):
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py", line 28, in <module>
    consume_kafka_data = ConsumeFromTopicOperator(
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'topics'
[2023-11-01T00:34:16.660+0000] {processor.py:841} WARNING - No viable dags retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:34:16.725+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.098 seconds
[2023-11-01T00:34:44.544+0000] {processor.py:157} INFO - Started process (PID=346127) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:34:44.545+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:34:44.545+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:34:44.545+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:34:44.554+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:34:44.552+0000] {dagbag.py:346} ERROR - Failed to import: /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
Traceback (most recent call last):
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py", line 28, in <module>
    consume_kafka_data = ConsumeFromTopicOperator(
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/providers/apache/kafka/operators/consume.py", line 91, in __init__
    super().__init__(**kwargs)
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 794, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to ConsumeFromTopicOperator (task_id: consume_kafka_data). Invalid arguments were:
**kwargs: {'task_ids': 'consume_kafka_data'}
[2023-11-01T00:34:44.554+0000] {processor.py:841} WARNING - No viable dags retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:34:44.604+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.064 seconds
[2023-11-01T00:35:14.837+0000] {processor.py:157} INFO - Started process (PID=346200) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:35:14.838+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:35:14.838+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:35:14.838+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:35:14.846+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:35:14.844+0000] {dagbag.py:346} ERROR - Failed to import: /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
Traceback (most recent call last):
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py", line 28, in <module>
    consume_kafka_data = ConsumeFromTopicOperator(
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/providers/apache/kafka/operators/consume.py", line 91, in __init__
    super().__init__(**kwargs)
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 794, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to ConsumeFromTopicOperator (task_id: consume_kafka_data). Invalid arguments were:
**kwargs: {'task_ids': 'consume_kafka_data'}
[2023-11-01T00:35:14.846+0000] {processor.py:841} WARNING - No viable dags retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:35:14.896+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.063 seconds
[2023-11-01T00:35:45.183+0000] {processor.py:157} INFO - Started process (PID=346211) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:35:45.184+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:35:45.184+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:35:45.184+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:35:45.192+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:35:45.191+0000] {dagbag.py:346} ERROR - Failed to import: /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
Traceback (most recent call last):
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py", line 28, in <module>
    consume_kafka_data = ConsumeFromTopicOperator(
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/providers/apache/kafka/operators/consume.py", line 91, in __init__
    super().__init__(**kwargs)
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 794, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to ConsumeFromTopicOperator (task_id: consume_kafka_data). Invalid arguments were:
**kwargs: {'task_ids': 'consume_kafka_data'}
[2023-11-01T00:35:45.192+0000] {processor.py:841} WARNING - No viable dags retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:35:45.277+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.097 seconds
[2023-11-01T00:36:15.526+0000] {processor.py:157} INFO - Started process (PID=346222) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:36:15.528+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:36:15.528+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:36:15.528+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:36:15.536+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:36:15.534+0000] {dagbag.py:346} ERROR - Failed to import: /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
Traceback (most recent call last):
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py", line 28, in <module>
    consume_kafka_data = ConsumeFromTopicOperator(
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/providers/apache/kafka/operators/consume.py", line 91, in __init__
    super().__init__(**kwargs)
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 794, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to ConsumeFromTopicOperator (task_id: consume_kafka_data). Invalid arguments were:
**kwargs: {'task_ids': 'consume_kafka_data'}
[2023-11-01T00:36:15.536+0000] {processor.py:841} WARNING - No viable dags retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:36:15.594+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.072 seconds
[2023-11-01T00:36:45.834+0000] {processor.py:157} INFO - Started process (PID=346233) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:36:45.835+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:36:45.836+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:36:45.836+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:36:45.843+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:36:45.842+0000] {dagbag.py:346} ERROR - Failed to import: /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
Traceback (most recent call last):
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py", line 28, in <module>
    consume_kafka_data = ConsumeFromTopicOperator(
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/providers/apache/kafka/operators/consume.py", line 91, in __init__
    super().__init__(**kwargs)
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 794, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to ConsumeFromTopicOperator (task_id: consume_kafka_data). Invalid arguments were:
**kwargs: {'task_ids': 'consume_kafka_data'}
[2023-11-01T00:36:45.843+0000] {processor.py:841} WARNING - No viable dags retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:36:45.894+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.064 seconds
[2023-11-01T00:37:16.252+0000] {processor.py:157} INFO - Started process (PID=346244) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:37:16.253+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:37:16.254+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:37:16.253+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:37:16.261+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:37:16.260+0000] {dagbag.py:346} ERROR - Failed to import: /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
Traceback (most recent call last):
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py", line 28, in <module>
    consume_kafka_data = ConsumeFromTopicOperator(
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/providers/apache/kafka/operators/consume.py", line 91, in __init__
    super().__init__(**kwargs)
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 794, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to ConsumeFromTopicOperator (task_id: consume_kafka_data). Invalid arguments were:
**kwargs: {'task_ids': 'consume_kafka_data'}
[2023-11-01T00:37:16.261+0000] {processor.py:841} WARNING - No viable dags retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:37:16.317+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.068 seconds
[2023-11-01T00:37:46.567+0000] {processor.py:157} INFO - Started process (PID=346255) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:37:46.568+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:37:46.568+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:37:46.568+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:37:46.576+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:37:46.575+0000] {dagbag.py:346} ERROR - Failed to import: /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
Traceback (most recent call last):
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py", line 28, in <module>
    consume_kafka_data = ConsumeFromTopicOperator(
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/providers/apache/kafka/operators/consume.py", line 91, in __init__
    super().__init__(**kwargs)
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 794, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to ConsumeFromTopicOperator (task_id: consume_kafka_data). Invalid arguments were:
**kwargs: {'task_ids': 'consume_kafka_data'}
[2023-11-01T00:37:46.576+0000] {processor.py:841} WARNING - No viable dags retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:37:46.625+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.061 seconds
[2023-11-01T00:38:16.858+0000] {processor.py:157} INFO - Started process (PID=346276) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:38:16.858+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:38:16.859+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:38:16.859+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:38:16.866+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:38:16.865+0000] {dagbag.py:346} ERROR - Failed to import: /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
Traceback (most recent call last):
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py", line 28, in <module>
    consume_kafka_data = ConsumeFromTopicOperator(
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/providers/apache/kafka/operators/consume.py", line 91, in __init__
    super().__init__(**kwargs)
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/ubuntu/development/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 794, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to ConsumeFromTopicOperator (task_id: consume_kafka_data). Invalid arguments were:
**kwargs: {'task_ids': 'consume_kafka_data'}
[2023-11-01T00:38:16.867+0000] {processor.py:841} WARNING - No viable dags retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:38:16.923+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.069 seconds
[2023-11-01T00:38:25.936+0000] {processor.py:157} INFO - Started process (PID=346281) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:38:25.938+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:38:25.938+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:38:25.938+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:38:25.948+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:38:25.948+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:38:25.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:38:26.199+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:38:26.199+0000] {manager.py:499} INFO - Created Permission View: %s
[2023-11-01T00:38:26.222+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:38:26.221+0000] {manager.py:499} INFO - Created Permission View: %s
[2023-11-01T00:38:26.238+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:38:26.238+0000] {manager.py:499} INFO - Created Permission View: %s
[2023-11-01T00:38:26.239+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:38:26.239+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:38:26.260+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:38:26.260+0000] {dag.py:2963} INFO - Creating ORM DAG for consume_and_process_kafka_data
[2023-11-01T00:38:26.281+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:38:26.280+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:33:26.280442+00:00, run_after=2023-11-01T00:38:26.280442+00:00
[2023-11-01T00:38:26.321+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.389 seconds
[2023-11-01T00:38:56.589+0000] {processor.py:157} INFO - Started process (PID=346352) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:38:56.590+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:38:56.591+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:38:56.590+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:38:56.599+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:38:56.599+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:38:56.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:38:56.703+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:38:56.702+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:38:56.750+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:38:56.750+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:33:56.750012+00:00, run_after=2023-11-01T00:38:56.750012+00:00
[2023-11-01T00:38:56.796+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.212 seconds
[2023-11-01T00:39:19.005+0000] {processor.py:157} INFO - Started process (PID=346490) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:39:19.006+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:39:19.007+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:39:19.007+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:39:19.014+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:39:19.014+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:39:19.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:39:19.164+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:39:19.164+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:39:19.184+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:39:19.184+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:34:19.183994+00:00, run_after=2023-11-01T00:39:19.183994+00:00
[2023-11-01T00:39:19.222+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.221 seconds
[2023-11-01T00:39:33.897+0000] {processor.py:157} INFO - Started process (PID=346501) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:39:33.898+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:39:33.899+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:39:33.898+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:39:33.906+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:39:33.906+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:39:33.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:39:33.961+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:39:33.961+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:39:33.984+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:39:33.983+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:34:33.983737+00:00, run_after=2023-11-01T00:39:33.983737+00:00
[2023-11-01T00:39:34.017+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.124 seconds
[2023-11-01T00:40:04.259+0000] {processor.py:157} INFO - Started process (PID=346512) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:40:04.260+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:40:04.260+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:40:04.260+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:40:04.267+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:40:04.267+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:40:04.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:40:04.327+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:40:04.327+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:40:04.351+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:40:04.351+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:35:04.351098+00:00, run_after=2023-11-01T00:40:04.351098+00:00
[2023-11-01T00:40:04.384+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.128 seconds
[2023-11-01T00:40:34.630+0000] {processor.py:157} INFO - Started process (PID=346523) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:40:34.631+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:40:34.632+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:40:34.631+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:40:34.638+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:40:34.638+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:40:34.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:40:34.695+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:40:34.695+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:40:34.721+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:40:34.721+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:35:34.721022+00:00, run_after=2023-11-01T00:40:34.721022+00:00
[2023-11-01T00:40:34.752+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.125 seconds
[2023-11-01T00:41:04.983+0000] {processor.py:157} INFO - Started process (PID=346534) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:41:04.984+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:41:04.984+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:41:04.984+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:41:04.991+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:41:04.991+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:41:04.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:41:05.049+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:41:05.049+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:41:05.077+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:41:05.077+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:36:05.077026+00:00, run_after=2023-11-01T00:41:05.077026+00:00
[2023-11-01T00:41:05.112+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.133 seconds
[2023-11-01T00:41:35.348+0000] {processor.py:157} INFO - Started process (PID=346545) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:41:35.349+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:41:35.349+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:41:35.349+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:41:35.356+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:41:35.356+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:41:35.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:41:35.448+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:41:35.448+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:41:35.471+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:41:35.471+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:36:35.471246+00:00, run_after=2023-11-01T00:41:35.471246+00:00
[2023-11-01T00:41:35.516+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.172 seconds
[2023-11-01T00:42:05.754+0000] {processor.py:157} INFO - Started process (PID=346556) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:42:05.755+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:42:05.755+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:42:05.755+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:42:05.762+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:42:05.762+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:42:05.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:42:05.825+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:42:05.825+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:42:05.848+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:42:05.847+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:37:05.847609+00:00, run_after=2023-11-01T00:42:05.847609+00:00
[2023-11-01T00:42:05.887+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.137 seconds
[2023-11-01T00:42:36.141+0000] {processor.py:157} INFO - Started process (PID=346567) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:42:36.142+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:42:36.143+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:42:36.143+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:42:36.149+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:42:36.149+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:42:36.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:42:36.211+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:42:36.211+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:42:36.232+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:42:36.232+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:37:36.232617+00:00, run_after=2023-11-01T00:42:36.232617+00:00
[2023-11-01T00:42:36.265+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.127 seconds
[2023-11-01T00:43:06.504+0000] {processor.py:157} INFO - Started process (PID=346578) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:43:06.505+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:43:06.506+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:43:06.505+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:43:06.512+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:43:06.512+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:43:06.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:43:06.570+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:43:06.570+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:43:06.593+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:43:06.593+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:38:06.593571+00:00, run_after=2023-11-01T00:43:06.593571+00:00
[2023-11-01T00:43:06.626+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.125 seconds
[2023-11-01T00:43:36.859+0000] {processor.py:157} INFO - Started process (PID=346589) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:43:36.860+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:43:36.860+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:43:36.860+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:43:36.866+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:43:36.866+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:43:36.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:43:36.931+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:43:36.931+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:43:36.954+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:43:36.954+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:38:36.953901+00:00, run_after=2023-11-01T00:43:36.953901+00:00
[2023-11-01T00:43:36.990+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.136 seconds
[2023-11-01T00:44:07.233+0000] {processor.py:157} INFO - Started process (PID=346600) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:44:07.234+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:44:07.235+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:44:07.234+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:44:07.241+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:44:07.241+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:44:07.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:44:07.309+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:44:07.308+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:44:07.332+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:44:07.332+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:39:07.331942+00:00, run_after=2023-11-01T00:44:07.331942+00:00
[2023-11-01T00:44:07.369+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.140 seconds
[2023-11-01T00:44:37.499+0000] {processor.py:157} INFO - Started process (PID=346731) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:44:37.502+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:44:37.503+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:44:37.503+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:44:37.514+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:44:37.514+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:44:37.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:44:37.641+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:44:37.641+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:44:37.686+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:44:37.684+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:39:37.684593+00:00, run_after=2023-11-01T00:44:37.684593+00:00
[2023-11-01T00:44:37.729+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.234 seconds
[2023-11-01T00:45:07.966+0000] {processor.py:157} INFO - Started process (PID=346742) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:45:07.967+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:45:07.968+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:45:07.967+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:45:07.974+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:45:07.974+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:45:07.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:45:08.035+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:45:08.035+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:45:08.058+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:45:08.058+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:40:08.058154+00:00, run_after=2023-11-01T00:45:08.058154+00:00
[2023-11-01T00:45:08.098+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.135 seconds
[2023-11-01T00:45:38.348+0000] {processor.py:157} INFO - Started process (PID=346753) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:45:38.349+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:45:38.350+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:45:38.350+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:45:38.357+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:45:38.357+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:45:38.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:45:38.416+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:45:38.416+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:45:38.440+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:45:38.440+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:40:38.440166+00:00, run_after=2023-11-01T00:45:38.440166+00:00
[2023-11-01T00:45:38.474+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.129 seconds
[2023-11-01T00:46:08.716+0000] {processor.py:157} INFO - Started process (PID=346764) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:46:08.717+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:46:08.718+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:46:08.718+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:46:08.725+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:46:08.724+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:46:08.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:46:08.786+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:46:08.786+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:46:08.811+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:46:08.811+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:41:08.811577+00:00, run_after=2023-11-01T00:46:08.811577+00:00
[2023-11-01T00:46:08.844+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.131 seconds
[2023-11-01T00:46:39.092+0000] {processor.py:157} INFO - Started process (PID=346775) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:46:39.093+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:46:39.094+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:46:39.094+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:46:39.101+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:46:39.101+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:46:39.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:46:39.157+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:46:39.157+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:46:39.179+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:46:39.179+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:41:39.179533+00:00, run_after=2023-11-01T00:46:39.179533+00:00
[2023-11-01T00:46:39.210+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.123 seconds
[2023-11-01T00:47:09.456+0000] {processor.py:157} INFO - Started process (PID=346786) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:47:09.457+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:47:09.458+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:47:09.457+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:47:09.465+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:47:09.465+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:47:09.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:47:09.545+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:47:09.545+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:47:09.567+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:47:09.567+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:42:09.567258+00:00, run_after=2023-11-01T00:47:09.567258+00:00
[2023-11-01T00:47:09.600+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.147 seconds
[2023-11-01T00:47:39.864+0000] {processor.py:157} INFO - Started process (PID=346797) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:47:39.866+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:47:39.866+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:47:39.866+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:47:39.873+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:47:39.872+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:47:39.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:47:39.930+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:47:39.930+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:47:39.951+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:47:39.951+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:42:39.951437+00:00, run_after=2023-11-01T00:47:39.951437+00:00
[2023-11-01T00:47:39.983+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.122 seconds
[2023-11-01T00:48:10.228+0000] {processor.py:157} INFO - Started process (PID=346808) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:48:10.229+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:48:10.229+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:48:10.229+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:48:10.236+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:48:10.236+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:48:10.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:48:10.294+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:48:10.294+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:48:10.317+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:48:10.317+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:43:10.317030+00:00, run_after=2023-11-01T00:48:10.317030+00:00
[2023-11-01T00:48:10.349+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.124 seconds
[2023-11-01T00:48:40.644+0000] {processor.py:157} INFO - Started process (PID=346819) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:48:40.645+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:48:40.646+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:48:40.646+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:48:40.653+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:48:40.653+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:48:40.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:48:40.712+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:48:40.712+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:48:40.739+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:48:40.738+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:43:40.738653+00:00, run_after=2023-11-01T00:48:40.738653+00:00
[2023-11-01T00:48:40.779+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.139 seconds
[2023-11-01T00:49:11.021+0000] {processor.py:157} INFO - Started process (PID=346830) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:49:11.022+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:49:11.023+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:49:11.022+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:49:11.030+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:49:11.030+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:49:11.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:49:11.102+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:49:11.102+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:49:11.124+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:49:11.124+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:44:11.123806+00:00, run_after=2023-11-01T00:49:11.123806+00:00
[2023-11-01T00:49:11.155+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.138 seconds
[2023-11-01T00:49:41.392+0000] {processor.py:157} INFO - Started process (PID=346967) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:49:41.393+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:49:41.394+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:49:41.394+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:49:41.401+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:49:41.400+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:49:41.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:49:41.474+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:49:41.474+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:49:41.498+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:49:41.498+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:44:41.498132+00:00, run_after=2023-11-01T00:49:41.498132+00:00
[2023-11-01T00:49:41.534+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.145 seconds
[2023-11-01T00:50:11.782+0000] {processor.py:157} INFO - Started process (PID=346978) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:50:11.783+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:50:11.783+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:50:11.783+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:50:11.791+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:50:11.790+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:50:11.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:50:11.849+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:50:11.849+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:50:11.872+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:50:11.872+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:45:11.872368+00:00, run_after=2023-11-01T00:50:11.872368+00:00
[2023-11-01T00:50:11.903+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.125 seconds
[2023-11-01T00:50:42.159+0000] {processor.py:157} INFO - Started process (PID=346989) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:50:42.160+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:50:42.161+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:50:42.161+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:50:42.167+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:50:42.167+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:50:42.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:50:42.229+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:50:42.229+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:50:42.260+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:50:42.260+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:45:42.260258+00:00, run_after=2023-11-01T00:50:42.260258+00:00
[2023-11-01T00:50:42.305+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.150 seconds
[2023-11-01T00:51:12.560+0000] {processor.py:157} INFO - Started process (PID=347000) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:51:12.561+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:51:12.562+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:51:12.562+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:51:12.568+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:51:12.568+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:51:12.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:51:12.630+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:51:12.630+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:51:12.658+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:51:12.658+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:46:12.658016+00:00, run_after=2023-11-01T00:51:12.658016+00:00
[2023-11-01T00:51:12.696+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.139 seconds
[2023-11-01T00:51:42.931+0000] {processor.py:157} INFO - Started process (PID=347011) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:51:42.931+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:51:42.932+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:51:42.932+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:51:42.939+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:51:42.938+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:51:42.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:51:43.001+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:51:43.000+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:51:43.023+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:51:43.023+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:46:43.023268+00:00, run_after=2023-11-01T00:51:43.023268+00:00
[2023-11-01T00:51:43.056+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.128 seconds
[2023-11-01T00:52:13.313+0000] {processor.py:157} INFO - Started process (PID=347029) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:52:13.314+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:52:13.315+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:52:13.315+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:52:13.322+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:52:13.322+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:52:13.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:52:13.380+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:52:13.380+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:52:13.403+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:52:13.402+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:47:13.402703+00:00, run_after=2023-11-01T00:52:13.402703+00:00
[2023-11-01T00:52:13.438+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.128 seconds
[2023-11-01T00:52:43.696+0000] {processor.py:157} INFO - Started process (PID=347040) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:52:43.696+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:52:43.697+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:52:43.697+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:52:43.703+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:52:43.703+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:52:43.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:52:43.764+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:52:43.764+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:52:43.785+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:52:43.785+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:47:43.785207+00:00, run_after=2023-11-01T00:52:43.785207+00:00
[2023-11-01T00:52:43.817+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.125 seconds
[2023-11-01T00:53:14.058+0000] {processor.py:157} INFO - Started process (PID=347051) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:53:14.059+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:53:14.059+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:53:14.059+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:53:14.066+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:53:14.066+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:53:14.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:53:14.135+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:53:14.135+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:53:14.160+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:53:14.160+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:48:14.160274+00:00, run_after=2023-11-01T00:53:14.160274+00:00
[2023-11-01T00:53:14.196+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.142 seconds
[2023-11-01T00:53:44.445+0000] {processor.py:157} INFO - Started process (PID=347062) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:53:44.446+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:53:44.446+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:53:44.446+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:53:44.453+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:53:44.453+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:53:44.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:53:44.515+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:53:44.514+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:53:44.539+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:53:44.539+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:48:44.539558+00:00, run_after=2023-11-01T00:53:44.539558+00:00
[2023-11-01T00:53:44.579+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.137 seconds
[2023-11-01T00:54:14.816+0000] {processor.py:157} INFO - Started process (PID=347073) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:54:14.817+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:54:14.818+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:54:14.818+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:54:14.824+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:54:14.824+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:54:14.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:54:14.883+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:54:14.882+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:54:14.906+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:54:14.906+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:49:14.905924+00:00, run_after=2023-11-01T00:54:14.905924+00:00
[2023-11-01T00:54:14.941+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.129 seconds
[2023-11-01T00:54:45.177+0000] {processor.py:157} INFO - Started process (PID=347210) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:54:45.177+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:54:45.178+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:54:45.178+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:54:45.185+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:54:45.184+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:54:45.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:54:45.252+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:54:45.252+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:54:45.275+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:54:45.275+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:49:45.275259+00:00, run_after=2023-11-01T00:54:45.275259+00:00
[2023-11-01T00:54:45.317+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.143 seconds
[2023-11-01T00:55:15.558+0000] {processor.py:157} INFO - Started process (PID=347221) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:55:15.559+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:55:15.560+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:55:15.560+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:55:15.566+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:55:15.566+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:55:15.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:55:15.624+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:55:15.624+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:55:15.647+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:55:15.647+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:50:15.647228+00:00, run_after=2023-11-01T00:55:15.647228+00:00
[2023-11-01T00:55:15.678+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.124 seconds
[2023-11-01T00:55:45.915+0000] {processor.py:157} INFO - Started process (PID=347232) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:55:45.916+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:55:45.917+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:55:45.916+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:55:45.924+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:55:45.924+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:55:45.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:55:45.982+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:55:45.982+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:55:46.011+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:55:46.010+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:50:46.010721+00:00, run_after=2023-11-01T00:55:46.010721+00:00
[2023-11-01T00:55:46.046+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.134 seconds
[2023-11-01T00:56:16.285+0000] {processor.py:157} INFO - Started process (PID=347243) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:56:16.286+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:56:16.287+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:56:16.286+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:56:16.293+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:56:16.293+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:56:16.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:56:16.355+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:56:16.355+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:56:16.377+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:56:16.377+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:51:16.377479+00:00, run_after=2023-11-01T00:56:16.377479+00:00
[2023-11-01T00:56:16.410+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.128 seconds
[2023-11-01T00:56:46.659+0000] {processor.py:157} INFO - Started process (PID=347254) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:56:46.660+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:56:46.661+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:56:46.660+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:56:46.667+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:56:46.667+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:56:46.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:56:46.747+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:56:46.746+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:56:46.770+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:56:46.770+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:51:46.769978+00:00, run_after=2023-11-01T00:56:46.769978+00:00
[2023-11-01T00:56:46.801+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.145 seconds
[2023-11-01T00:57:17.041+0000] {processor.py:157} INFO - Started process (PID=347265) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:57:17.042+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:57:17.043+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:57:17.043+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:57:17.049+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:57:17.049+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:57:17.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:57:17.109+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:57:17.108+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:57:17.132+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:57:17.132+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:52:17.132007+00:00, run_after=2023-11-01T00:57:17.132007+00:00
[2023-11-01T00:57:17.163+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.125 seconds
[2023-11-01T00:57:47.396+0000] {processor.py:157} INFO - Started process (PID=347276) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:57:47.396+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:57:47.397+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:57:47.397+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:57:47.404+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:57:47.404+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:57:47.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:57:47.474+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:57:47.474+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:57:47.499+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:57:47.499+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:52:47.498854+00:00, run_after=2023-11-01T00:57:47.498854+00:00
[2023-11-01T00:57:47.534+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.141 seconds
[2023-11-01T00:58:17.769+0000] {processor.py:157} INFO - Started process (PID=347288) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:58:17.770+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:58:17.770+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:58:17.770+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:58:17.777+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:58:17.776+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:58:17.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:58:17.845+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:58:17.845+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:58:17.869+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:58:17.869+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:53:17.869485+00:00, run_after=2023-11-01T00:58:17.869485+00:00
[2023-11-01T00:58:17.906+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.141 seconds
[2023-11-01T00:58:48.146+0000] {processor.py:157} INFO - Started process (PID=347299) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:58:48.147+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:58:48.148+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:58:48.148+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:58:48.154+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:58:48.154+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:58:48.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:58:48.212+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:58:48.212+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:58:48.235+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:58:48.235+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:53:48.235578+00:00, run_after=2023-11-01T00:58:48.235578+00:00
[2023-11-01T00:58:48.268+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.125 seconds
[2023-11-01T00:59:18.512+0000] {processor.py:157} INFO - Started process (PID=347357) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:59:18.512+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:59:18.513+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:59:18.513+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:59:18.520+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:59:18.520+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:59:18.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:59:18.581+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:59:18.581+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:59:18.608+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:59:18.608+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:54:18.608412+00:00, run_after=2023-11-01T00:59:18.608412+00:00
[2023-11-01T00:59:18.647+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.139 seconds
[2023-11-01T00:59:48.892+0000] {processor.py:157} INFO - Started process (PID=347447) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:59:48.893+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T00:59:48.893+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:59:48.893+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:59:48.900+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:59:48.900+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T00:59:48.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T00:59:48.966+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:59:48.966+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T00:59:48.990+0000] {logging_mixin.py:151} INFO - [2023-11-01T00:59:48.990+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:54:48.989792+00:00, run_after=2023-11-01T00:59:48.989792+00:00
[2023-11-01T00:59:49.027+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.139 seconds
[2023-11-01T01:00:19.372+0000] {processor.py:157} INFO - Started process (PID=347458) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T01:00:19.372+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T01:00:19.373+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:00:19.373+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T01:00:19.380+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:00:19.379+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T01:00:19.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T01:00:19.441+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:00:19.441+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T01:00:19.471+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:00:19.470+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:55:19.470636+00:00, run_after=2023-11-01T01:00:19.470636+00:00
[2023-11-01T01:00:19.510+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.141 seconds
[2023-11-01T01:00:49.757+0000] {processor.py:157} INFO - Started process (PID=347469) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T01:00:49.758+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T01:00:49.759+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:00:49.758+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T01:00:49.765+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:00:49.765+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T01:00:49.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T01:00:49.840+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:00:49.840+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T01:00:49.863+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:00:49.863+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:55:49.863148+00:00, run_after=2023-11-01T01:00:49.863148+00:00
[2023-11-01T01:00:49.896+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.142 seconds
[2023-11-01T01:01:20.147+0000] {processor.py:157} INFO - Started process (PID=347480) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T01:01:20.147+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T01:01:20.148+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:01:20.148+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T01:01:20.155+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:01:20.154+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T01:01:20.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T01:01:20.214+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:01:20.214+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T01:01:20.237+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:01:20.237+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:56:20.237567+00:00, run_after=2023-11-01T01:01:20.237567+00:00
[2023-11-01T01:01:20.271+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.128 seconds
[2023-11-01T01:01:50.526+0000] {processor.py:157} INFO - Started process (PID=347492) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T01:01:50.528+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T01:01:50.528+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:01:50.528+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T01:01:50.535+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:01:50.535+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T01:01:50.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T01:01:50.593+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:01:50.593+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T01:01:50.616+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:01:50.616+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:56:50.616583+00:00, run_after=2023-11-01T01:01:50.616583+00:00
[2023-11-01T01:01:50.650+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.128 seconds
[2023-11-01T01:02:20.885+0000] {processor.py:157} INFO - Started process (PID=347503) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T01:02:20.886+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T01:02:20.887+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:02:20.887+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T01:02:20.893+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:02:20.893+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T01:02:20.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T01:02:20.958+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:02:20.958+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T01:02:20.981+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:02:20.981+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:57:20.980833+00:00, run_after=2023-11-01T01:02:20.980833+00:00
[2023-11-01T01:02:21.018+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.137 seconds
[2023-11-01T01:02:51.264+0000] {processor.py:157} INFO - Started process (PID=347514) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T01:02:51.265+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T01:02:51.266+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:02:51.265+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T01:02:51.272+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:02:51.272+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T01:02:51.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T01:02:51.330+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:02:51.330+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T01:02:51.354+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:02:51.354+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:57:51.353903+00:00, run_after=2023-11-01T01:02:51.353903+00:00
[2023-11-01T01:02:51.386+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.125 seconds
[2023-11-01T01:03:21.627+0000] {processor.py:157} INFO - Started process (PID=347528) to work on /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T01:03:21.628+0000] {processor.py:829} INFO - Processing file /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py for tasks to queue
[2023-11-01T01:03:21.629+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:03:21.629+0000] {dagbag.py:536} INFO - Filling up the DagBag from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T01:03:21.635+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:03:21.635+0000] {consume.py:115} WARNING - max_batch_size (1000) > max_messages (True). Setting max_messages to 1000
[2023-11-01T01:03:21.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['consume_and_process_kafka_data']) retrieved from /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py
[2023-11-01T01:03:21.696+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:03:21.695+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2023-11-01T01:03:21.718+0000] {logging_mixin.py:151} INFO - [2023-11-01T01:03:21.718+0000] {dag.py:3722} INFO - Setting next_dagrun for consume_and_process_kafka_data to 2023-11-01T00:58:21.718138+00:00, run_after=2023-11-01T01:03:21.718138+00:00
[2023-11-01T01:03:21.755+0000] {processor.py:179} INFO - Processing /home/ubuntu/data-engineering/airflow/dags/KafkaConsumerDag.py took 0.132 seconds
